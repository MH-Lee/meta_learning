{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.dataloader import MiniImagenet\n",
    "from proto.protonet import ConvNet, distance, accuracy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "K = 1\n",
    "Q = 15\n",
    "batch_size = 8\n",
    "meta_lr=0.003\n",
    "fast_lr=0.5\n",
    "adaptation_steps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(777)\n",
    "torch.cuda.manual_seed_all(777)\n",
    "np.random.seed(777)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:22<00:00, 2620.83it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2827.42it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 2871.85it/s]\n"
     ]
    }
   ],
   "source": [
    "root_path = './datasets/miniimagenet/pkl_file/' \n",
    "train_dataset = MiniImagenet(path=root_path, N=N, K=K, Q=Q, mode='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\\\n",
    "                          shuffle=True, num_workers=1)\n",
    "val_dataset = MiniImagenet(path=root_path, N=5, K=1, Q=Q,\\\n",
    "                           mode='validation', total_iter=1000)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,\\\n",
    "                        shuffle=True, num_workers=1)\n",
    "test_dataset = MiniImagenet(path=root_path, N=5, K=1, Q=Q,\\\n",
    "                            mode='test', total_iter=5000)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\\\n",
    "                         shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = list(zip(*task_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 84, 84])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx, sy, qx, qy = batch[0]\n",
    "sx.size(0)\n",
    "sx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/graph_rec/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "sx, sy, qx, qy = batch[0]\n",
    "sx, sy, qx, qy = sx.to(device), sy.to(device), qx.to(device), qy.to(device)\n",
    "NK = sx.size(0)\n",
    "support_indices = torch.sort(sy)\n",
    "query_indices = torch.sort(qy)\n",
    "sy = sy[support_indices.indices]\n",
    "qx = qx[query_indices.indices]\n",
    "qy = qy[query_indices.indices]\n",
    "data = torch.cat((sx,qx),dim=0)\n",
    "labels = qy.long()\n",
    "embeddings = model(data)\n",
    "support = embeddings[:NK]\n",
    "proto = support.reshape(5, 1, -1).mean(dim=1)\n",
    "query = embeddings[NK:]\n",
    "logits = distance(query, proto)\n",
    "loss = criterion(logits, labels)\n",
    "acc = accuracy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 1600])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = qy.long() \n",
    "predictions = logits.argmax(dim=1).view(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 4, 0, 0, 4, 4, 1, 4, 2, 1, 2, 2, 2, 1, 4, 1, 3, 2, 1, 1, 3, 3, 1,\n",
       "        0, 3, 2, 1, 2, 3, 2, 0, 4, 1, 1, 1, 1, 4, 2, 2, 1, 0, 1, 4, 4, 3, 3, 1,\n",
       "        1, 3, 3, 1, 1, 4, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "        2, 0, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions == targets).sum().float() / targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qy.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False,  True,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False,  True, False, False,  True,\n",
       "         True, False, False,  True, False, False, False,  True, False, False,\n",
       "         True, False, False, False, False, False, False, False,  True,  True,\n",
       "        False, False, False, False, False,  True,  True, False, False,  True,\n",
       "         True, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qy.long() == predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([75])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qy.long().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1600])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protnet_train(batch, model, metric, N, K, device):\n",
    "    sx, sy, qx, qy = batch\n",
    "    sx, sy, qx, qy = sx.to(device), sy.to(device), qx.to(device), qy.to(device)\n",
    "    NK = N * K\n",
    "    support_indices = torch.sort(sy)\n",
    "    query_indices = torch.sort(qy)\n",
    "    sx = sx[support_indices.indices]\n",
    "    sy = sy[support_indices.indices]\n",
    "    qx = qx[query_indices.indices]\n",
    "    qy = qy[query_indices.indices]\n",
    "    data = torch.cat((sx,qx),dim=0)\n",
    "    labels = qy.long()\n",
    "    embeddings = model(data)\n",
    "    support = embeddings[:NK]\n",
    "    query = embeddings[NK:]\n",
    "    proto = support.reshape(N, K, -1).mean(dim=1)\n",
    "    logits = metric(query, proto)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    acc = accuracy(logits, labels)\n",
    "    return loss, acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = protnet_train(batch, model, metric=distance, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2133333384990692"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model(data)\n",
    "support = embeddings[:N*K]\n",
    "query = embeddings[N*K:]\n",
    "proto = support.reshape(N, K, -1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5249, 1.0267, 0.5028,  ..., 0.8321, 1.7107, 2.2130],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.8166, 0.1553],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.1699, 1.1649, 0.0000,  ..., 0.4147, 1.3676, 0.9837],\n",
       "        [0.0810, 0.0000, 0.0000,  ..., 0.0673, 0.7102, 0.3721]],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = distance(query, support)\n",
    "labels = qy.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.cross_entropy(logits, labels)\n",
    "acc = accuracy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metric is None:\n",
    "    metric = pairwise_distances_logits\n",
    "if device is None:\n",
    "    device = model.device()\n",
    "data, labels = batch\n",
    "data = data.to(device)\n",
    "labels = labels.to(device)\n",
    "n_items = shot * ways\n",
    "\n",
    "# Sort data samples by labels\n",
    "# TODO: Can this be replaced by ConsecutiveLabels ?\n",
    "sort = torch.sort(labels)\n",
    "data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "# Compute support and query embeddings\n",
    "embeddings = model(data)\n",
    "support_indices = np.zeros(data.size(0), dtype=bool)\n",
    "selection = np.arange(ways) * (shot + query_num)\n",
    "for offset in range(shot):\n",
    "    support_indices[selection + offset] = True\n",
    "query_indices = torch.from_numpy(~support_indices)\n",
    "support_indices = torch.from_numpy(support_indices)\n",
    "support = embeddings[support_indices]\n",
    "support = support.reshape(ways, shot, -1).mean(dim=1)\n",
    "query = embeddings[query_indices]\n",
    "labels = labels[query_indices].long()\n",
    "\n",
    "logits = pairwise_distances_logits(query, support)\n",
    "loss = F.cross_entropy(logits, labels)\n",
    "acc = accuracy(logits, labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b04a425eb4e2f19ba39b3c02446514a59b882cc39dc361899bc0b5cea762b69"
  },
  "kernelspec": {
   "display_name": "graph_rec",
   "language": "python",
   "name": "graph_rec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

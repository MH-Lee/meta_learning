{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.dataloader import MiniImagenet\n",
    "from proto.protonet import ConvNet, distance, accuracy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(777)\n",
    "torch.cuda.manual_seed_all(777)\n",
    "np.random.seed(777)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances_logits(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    logits = -((a.unsqueeze(1).expand(n, m, -1) -\n",
    "                b.unsqueeze(0).expand(n, m, -1))**2).sum(dim=2)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)\n",
    "\n",
    "def fast_adapt(model, batch, ways, shot, query_num, metric=None, device=None):\n",
    "    if metric is None:\n",
    "        metric = pairwise_distances_logits\n",
    "    if device is None:\n",
    "        device = model.device()\n",
    "    data, labels = batch\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    n_items = shot * ways\n",
    "\n",
    "    # Sort data samples by labels\n",
    "    # TODO: Can this be replaced by ConsecutiveLabels ?\n",
    "    sort = torch.sort(labels)\n",
    "    data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "    labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "    # Compute support and query embeddings\n",
    "    embeddings = model(data)\n",
    "    support_indices = np.zeros(data.size(0), dtype=bool)\n",
    "    selection = np.arange(ways) * (shot + query_num)\n",
    "    for offset in range(shot):\n",
    "        support_indices[selection + offset] = True\n",
    "    query_indices = torch.from_numpy(~support_indices)\n",
    "    support_indices = torch.from_numpy(support_indices)\n",
    "    support = embeddings[support_indices]\n",
    "    support = support.reshape(ways, shot, -1).mean(dim=1)\n",
    "    query = embeddings[query_indices]\n",
    "    labels = labels[query_indices].long()\n",
    "\n",
    "    logits = pairwise_distances_logits(query, support)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    acc = accuracy(logits, labels)\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = EasyDict({\n",
    "    'max_epoch':250,\n",
    "    'train_ways':20,\n",
    "    'shot' : 1,\n",
    "    'train_query':15,\n",
    "    'test_ways': 5,\n",
    "    'test_shot' : 1,\n",
    "    'test_query':15,\n",
    "    'batch_size':1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:35<00:00, 711.70it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 2001.36it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 2691.19it/s]\n"
     ]
    }
   ],
   "source": [
    "root_path = './datasets/miniimagenet/pkl_file/' \n",
    "train_dataset = MiniImagenet(path=root_path, N=args.train_ways, K=args.shot, Q=args.train_query, \\\n",
    "                             mode='train', total_iter=25000,\\\n",
    "                             transform=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size,\\\n",
    "                          shuffle=True, num_workers=1)\n",
    "val_dataset = MiniImagenet(path=root_path, N=args.test_ways, K=args.test_shot, Q=args.test_query,\\\n",
    "                           mode='validation', total_iter=200,\\\n",
    "                           transform=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size,\\\n",
    "                        shuffle=True, num_workers=1)\n",
    "test_dataset = MiniImagenet(path=root_path, N=args.test_ways, K=args.test_shot, Q=args.test_query,\\\n",
    "                            mode='test', total_iter=2000,\\\n",
    "                            transform=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size,\\\n",
    "                         shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = ConvNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sx, sy, qx, qy = task_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/graph_rec/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train, loss=21.4716 acc=0.1090\n",
      "epoch 1, val, loss=2.2749 acc=0.2695\n",
      "epoch 2, train, loss=3.2944 acc=0.1064\n",
      "epoch 2, val, loss=1.7410 acc=0.2777\n",
      "epoch 3, train, loss=3.0188 acc=0.1142\n",
      "epoch 3, val, loss=1.6169 acc=0.3013\n",
      "epoch 4, train, loss=2.9225 acc=0.1297\n",
      "epoch 4, val, loss=1.5767 acc=0.3173\n",
      "epoch 5, train, loss=2.8752 acc=0.1376\n",
      "epoch 5, val, loss=1.5513 acc=0.3249\n",
      "epoch 6, train, loss=2.8512 acc=0.1419\n",
      "epoch 6, val, loss=1.5514 acc=0.3328\n",
      "epoch 7, train, loss=2.8202 acc=0.1502\n",
      "epoch 7, val, loss=1.5160 acc=0.3433\n",
      "epoch 8, train, loss=2.8233 acc=0.1440\n",
      "epoch 8, val, loss=1.5025 acc=0.3522\n",
      "epoch 9, train, loss=2.7951 acc=0.1533\n",
      "epoch 9, val, loss=1.5004 acc=0.3583\n",
      "epoch 10, train, loss=2.7790 acc=0.1551\n",
      "epoch 10, val, loss=1.4783 acc=0.3631\n",
      "epoch 11, train, loss=2.7474 acc=0.1742\n",
      "epoch 11, val, loss=1.4786 acc=0.3661\n",
      "epoch 12, train, loss=2.7601 acc=0.1666\n",
      "epoch 12, val, loss=1.4873 acc=0.3693\n",
      "epoch 13, train, loss=2.7089 acc=0.1810\n",
      "epoch 13, val, loss=1.4572 acc=0.3813\n",
      "epoch 14, train, loss=2.7078 acc=0.1798\n",
      "epoch 14, val, loss=1.4474 acc=0.3890\n",
      "epoch 15, train, loss=2.6984 acc=0.1855\n",
      "epoch 15, val, loss=1.4502 acc=0.3850\n",
      "epoch 16, train, loss=2.6927 acc=0.1871\n",
      "epoch 16, val, loss=1.4667 acc=0.3845\n",
      "epoch 17, train, loss=2.6839 acc=0.1900\n",
      "epoch 17, val, loss=1.4464 acc=0.3882\n",
      "epoch 18, train, loss=2.6657 acc=0.1930\n",
      "epoch 18, val, loss=1.4541 acc=0.3893\n",
      "epoch 19, train, loss=2.6652 acc=0.1966\n",
      "epoch 19, val, loss=1.4252 acc=0.4027\n",
      "epoch 20, train, loss=2.6931 acc=0.1838\n",
      "epoch 20, val, loss=1.4327 acc=0.3957\n",
      "epoch 21, train, loss=2.6297 acc=0.2005\n",
      "epoch 21, val, loss=1.4258 acc=0.4001\n",
      "epoch 22, train, loss=2.6248 acc=0.2046\n",
      "epoch 22, val, loss=1.4260 acc=0.3969\n",
      "epoch 23, train, loss=2.6094 acc=0.2065\n",
      "epoch 23, val, loss=1.4512 acc=0.3903\n",
      "epoch 24, train, loss=2.6008 acc=0.2106\n",
      "epoch 24, val, loss=1.3993 acc=0.4101\n",
      "epoch 25, train, loss=2.5950 acc=0.2100\n",
      "epoch 25, val, loss=1.4194 acc=0.4101\n",
      "epoch 26, train, loss=2.6140 acc=0.2067\n",
      "epoch 26, val, loss=1.4480 acc=0.3985\n",
      "epoch 27, train, loss=2.5869 acc=0.2167\n",
      "epoch 27, val, loss=1.4067 acc=0.4086\n",
      "epoch 28, train, loss=2.5964 acc=0.2149\n",
      "epoch 28, val, loss=1.4106 acc=0.4098\n",
      "epoch 29, train, loss=2.5721 acc=0.2167\n",
      "epoch 29, val, loss=1.3913 acc=0.4158\n",
      "epoch 30, train, loss=2.5463 acc=0.2276\n",
      "epoch 30, val, loss=1.4177 acc=0.4130\n",
      "epoch 31, train, loss=2.5566 acc=0.2195\n",
      "epoch 31, val, loss=1.4235 acc=0.4067\n",
      "epoch 32, train, loss=2.5718 acc=0.2214\n",
      "epoch 32, val, loss=1.3994 acc=0.4165\n",
      "epoch 33, train, loss=2.5312 acc=0.2302\n",
      "epoch 33, val, loss=1.3851 acc=0.4209\n",
      "epoch 34, train, loss=2.5501 acc=0.2292\n",
      "epoch 34, val, loss=1.4013 acc=0.4164\n",
      "epoch 35, train, loss=2.5413 acc=0.2293\n",
      "epoch 35, val, loss=1.3839 acc=0.4185\n",
      "epoch 36, train, loss=2.5461 acc=0.2249\n",
      "epoch 36, val, loss=1.4018 acc=0.4166\n",
      "epoch 37, train, loss=2.5353 acc=0.2301\n",
      "epoch 37, val, loss=1.4138 acc=0.4121\n",
      "epoch 38, train, loss=2.5330 acc=0.2307\n",
      "epoch 38, val, loss=1.3761 acc=0.4285\n",
      "epoch 39, train, loss=2.5249 acc=0.2319\n",
      "epoch 39, val, loss=1.3929 acc=0.4248\n",
      "epoch 40, train, loss=2.5089 acc=0.2343\n",
      "epoch 40, val, loss=1.4208 acc=0.4057\n",
      "epoch 41, train, loss=2.4822 acc=0.2441\n",
      "epoch 41, val, loss=1.3689 acc=0.4287\n",
      "epoch 42, train, loss=2.4686 acc=0.2405\n",
      "epoch 42, val, loss=1.3648 acc=0.4347\n",
      "epoch 43, train, loss=2.4720 acc=0.2463\n",
      "epoch 43, val, loss=1.3626 acc=0.4326\n",
      "epoch 44, train, loss=2.4723 acc=0.2478\n",
      "epoch 44, val, loss=1.3830 acc=0.4296\n",
      "epoch 45, train, loss=2.4482 acc=0.2549\n",
      "epoch 45, val, loss=1.3682 acc=0.4303\n",
      "epoch 46, train, loss=2.4647 acc=0.2466\n",
      "epoch 46, val, loss=1.3908 acc=0.4305\n",
      "epoch 47, train, loss=2.4424 acc=0.2517\n",
      "epoch 47, val, loss=1.3545 acc=0.4383\n",
      "epoch 48, train, loss=2.4596 acc=0.2480\n",
      "epoch 48, val, loss=1.3651 acc=0.4313\n",
      "epoch 49, train, loss=2.4694 acc=0.2467\n",
      "epoch 49, val, loss=1.3926 acc=0.4291\n",
      "epoch 50, train, loss=2.4715 acc=0.2424\n",
      "epoch 50, val, loss=1.4050 acc=0.4140\n",
      "epoch 51, train, loss=2.4616 acc=0.2485\n",
      "epoch 51, val, loss=1.3460 acc=0.4499\n",
      "epoch 52, train, loss=2.4531 acc=0.2452\n",
      "epoch 52, val, loss=1.3605 acc=0.4387\n",
      "epoch 53, train, loss=2.4500 acc=0.2542\n",
      "epoch 53, val, loss=1.3650 acc=0.4357\n",
      "epoch 54, train, loss=2.4172 acc=0.2605\n",
      "epoch 54, val, loss=1.3576 acc=0.4396\n",
      "epoch 55, train, loss=2.4146 acc=0.2608\n",
      "epoch 55, val, loss=1.3336 acc=0.4511\n",
      "epoch 56, train, loss=2.4304 acc=0.2602\n",
      "epoch 56, val, loss=1.3705 acc=0.4391\n",
      "epoch 57, train, loss=2.4162 acc=0.2669\n",
      "epoch 57, val, loss=1.3460 acc=0.4438\n",
      "epoch 58, train, loss=2.4110 acc=0.2565\n",
      "epoch 58, val, loss=1.3516 acc=0.4397\n",
      "epoch 59, train, loss=2.4247 acc=0.2506\n",
      "epoch 59, val, loss=1.3485 acc=0.4421\n",
      "epoch 60, train, loss=2.3909 acc=0.2669\n",
      "epoch 60, val, loss=1.3741 acc=0.4361\n",
      "epoch 61, train, loss=2.3742 acc=0.2746\n",
      "epoch 61, val, loss=1.3387 acc=0.4501\n",
      "epoch 62, train, loss=2.3780 acc=0.2694\n",
      "epoch 62, val, loss=1.3428 acc=0.4517\n",
      "epoch 63, train, loss=2.3779 acc=0.2684\n",
      "epoch 63, val, loss=1.3312 acc=0.4558\n",
      "epoch 64, train, loss=2.3608 acc=0.2769\n",
      "epoch 64, val, loss=1.3326 acc=0.4522\n",
      "epoch 65, train, loss=2.3875 acc=0.2677\n",
      "epoch 65, val, loss=1.3440 acc=0.4473\n",
      "epoch 66, train, loss=2.3883 acc=0.2653\n",
      "epoch 66, val, loss=1.3281 acc=0.4545\n",
      "epoch 67, train, loss=2.3531 acc=0.2739\n",
      "epoch 67, val, loss=1.3385 acc=0.4517\n",
      "epoch 68, train, loss=2.3580 acc=0.2759\n",
      "epoch 68, val, loss=1.3557 acc=0.4461\n",
      "epoch 69, train, loss=2.3870 acc=0.2650\n",
      "epoch 69, val, loss=1.3220 acc=0.4595\n",
      "epoch 70, train, loss=2.3646 acc=0.2696\n",
      "epoch 70, val, loss=1.3595 acc=0.4427\n",
      "epoch 71, train, loss=2.3619 acc=0.2679\n",
      "epoch 71, val, loss=1.3372 acc=0.4491\n",
      "epoch 72, train, loss=2.3553 acc=0.2800\n",
      "epoch 72, val, loss=1.3392 acc=0.4533\n",
      "epoch 73, train, loss=2.3360 acc=0.2789\n",
      "epoch 73, val, loss=1.3183 acc=0.4572\n",
      "epoch 74, train, loss=2.3692 acc=0.2659\n",
      "epoch 74, val, loss=1.3298 acc=0.4547\n",
      "epoch 75, train, loss=2.3824 acc=0.2676\n",
      "epoch 75, val, loss=1.3189 acc=0.4586\n",
      "epoch 76, train, loss=2.3649 acc=0.2736\n",
      "epoch 76, val, loss=1.3347 acc=0.4505\n",
      "epoch 77, train, loss=2.3414 acc=0.2780\n",
      "epoch 77, val, loss=1.3255 acc=0.4578\n",
      "epoch 78, train, loss=2.3524 acc=0.2736\n",
      "epoch 78, val, loss=1.3282 acc=0.4561\n",
      "epoch 79, train, loss=2.3485 acc=0.2829\n",
      "epoch 79, val, loss=1.3220 acc=0.4569\n",
      "epoch 80, train, loss=2.3460 acc=0.2748\n",
      "epoch 80, val, loss=1.3179 acc=0.4598\n",
      "epoch 81, train, loss=2.3326 acc=0.2824\n",
      "epoch 81, val, loss=1.3222 acc=0.4589\n",
      "epoch 82, train, loss=2.3115 acc=0.2869\n",
      "epoch 82, val, loss=1.3267 acc=0.4571\n",
      "epoch 83, train, loss=2.3252 acc=0.2869\n",
      "epoch 83, val, loss=1.3266 acc=0.4555\n",
      "epoch 84, train, loss=2.2999 acc=0.2937\n",
      "epoch 84, val, loss=1.3228 acc=0.4575\n",
      "epoch 85, train, loss=2.3289 acc=0.2803\n",
      "epoch 85, val, loss=1.3112 acc=0.4616\n",
      "epoch 86, train, loss=2.3077 acc=0.2877\n",
      "epoch 86, val, loss=1.3176 acc=0.4599\n",
      "epoch 87, train, loss=2.3217 acc=0.2818\n",
      "epoch 87, val, loss=1.3109 acc=0.4611\n",
      "epoch 88, train, loss=2.3212 acc=0.2872\n",
      "epoch 88, val, loss=1.3250 acc=0.4593\n",
      "epoch 89, train, loss=2.3166 acc=0.2837\n",
      "epoch 89, val, loss=1.3125 acc=0.4621\n",
      "epoch 90, train, loss=2.3053 acc=0.2869\n",
      "epoch 90, val, loss=1.3164 acc=0.4633\n",
      "epoch 91, train, loss=2.3150 acc=0.2839\n",
      "epoch 91, val, loss=1.3111 acc=0.4637\n",
      "epoch 92, train, loss=2.3111 acc=0.2851\n",
      "epoch 92, val, loss=1.3098 acc=0.4646\n",
      "epoch 93, train, loss=2.3244 acc=0.2797\n",
      "epoch 93, val, loss=1.3203 acc=0.4593\n",
      "epoch 94, train, loss=2.3079 acc=0.2883\n",
      "epoch 94, val, loss=1.3215 acc=0.4569\n",
      "epoch 95, train, loss=2.2977 acc=0.2943\n",
      "epoch 95, val, loss=1.3128 acc=0.4654\n",
      "epoch 96, train, loss=2.3151 acc=0.2803\n",
      "epoch 96, val, loss=1.3052 acc=0.4699\n",
      "epoch 97, train, loss=2.3124 acc=0.2876\n",
      "epoch 97, val, loss=1.3077 acc=0.4679\n",
      "epoch 98, train, loss=2.2786 acc=0.2965\n",
      "epoch 98, val, loss=1.3045 acc=0.4683\n",
      "epoch 99, train, loss=2.3297 acc=0.2859\n",
      "epoch 99, val, loss=1.3128 acc=0.4639\n",
      "epoch 100, train, loss=2.2954 acc=0.2968\n",
      "epoch 100, val, loss=1.3187 acc=0.4619\n",
      "epoch 101, train, loss=2.2758 acc=0.2941\n",
      "epoch 101, val, loss=1.3144 acc=0.4616\n",
      "epoch 102, train, loss=2.2553 acc=0.3034\n",
      "epoch 102, val, loss=1.3105 acc=0.4645\n",
      "epoch 103, train, loss=2.2757 acc=0.2929\n",
      "epoch 103, val, loss=1.3175 acc=0.4636\n",
      "epoch 104, train, loss=2.2887 acc=0.2929\n",
      "epoch 104, val, loss=1.3024 acc=0.4656\n",
      "epoch 105, train, loss=2.2721 acc=0.2936\n",
      "epoch 105, val, loss=1.3051 acc=0.4668\n",
      "epoch 106, train, loss=2.2977 acc=0.2864\n",
      "epoch 106, val, loss=1.3192 acc=0.4621\n",
      "epoch 107, train, loss=2.2954 acc=0.2919\n",
      "epoch 107, val, loss=1.3032 acc=0.4693\n",
      "epoch 108, train, loss=2.2833 acc=0.2965\n",
      "epoch 108, val, loss=1.3143 acc=0.4635\n",
      "epoch 109, train, loss=2.2610 acc=0.2998\n",
      "epoch 109, val, loss=1.3060 acc=0.4643\n",
      "epoch 110, train, loss=2.2752 acc=0.2939\n",
      "epoch 110, val, loss=1.3027 acc=0.4671\n",
      "epoch 111, train, loss=2.2929 acc=0.2885\n",
      "epoch 111, val, loss=1.3069 acc=0.4668\n",
      "epoch 112, train, loss=2.2669 acc=0.2947\n",
      "epoch 112, val, loss=1.3025 acc=0.4683\n",
      "epoch 113, train, loss=2.2961 acc=0.2922\n",
      "epoch 113, val, loss=1.3068 acc=0.4661\n",
      "epoch 114, train, loss=2.3025 acc=0.2874\n",
      "epoch 114, val, loss=1.3062 acc=0.4649\n",
      "epoch 115, train, loss=2.2650 acc=0.3028\n",
      "epoch 115, val, loss=1.3046 acc=0.4671\n",
      "epoch 116, train, loss=2.2629 acc=0.3013\n",
      "epoch 116, val, loss=1.3145 acc=0.4628\n",
      "epoch 117, train, loss=2.2777 acc=0.2944\n",
      "epoch 117, val, loss=1.3132 acc=0.4621\n",
      "epoch 118, train, loss=2.2758 acc=0.2939\n",
      "epoch 118, val, loss=1.3051 acc=0.4692\n",
      "epoch 119, train, loss=2.2809 acc=0.2951\n",
      "epoch 119, val, loss=1.3085 acc=0.4643\n",
      "epoch 120, train, loss=2.2721 acc=0.2950\n",
      "epoch 120, val, loss=1.3119 acc=0.4627\n",
      "epoch 121, train, loss=2.3121 acc=0.2925\n",
      "epoch 121, val, loss=1.3040 acc=0.4667\n",
      "epoch 122, train, loss=2.2848 acc=0.2947\n",
      "epoch 122, val, loss=1.3041 acc=0.4685\n",
      "epoch 123, train, loss=2.2783 acc=0.2962\n",
      "epoch 123, val, loss=1.3028 acc=0.4681\n",
      "epoch 124, train, loss=2.2661 acc=0.2953\n",
      "epoch 124, val, loss=1.3066 acc=0.4701\n",
      "epoch 125, train, loss=2.3137 acc=0.2835\n",
      "epoch 125, val, loss=1.3037 acc=0.4683\n",
      "epoch 126, train, loss=2.2667 acc=0.2977\n",
      "epoch 126, val, loss=1.3026 acc=0.4680\n",
      "epoch 127, train, loss=2.2578 acc=0.3033\n",
      "epoch 127, val, loss=1.3017 acc=0.4670\n",
      "epoch 128, train, loss=2.2834 acc=0.2957\n",
      "epoch 128, val, loss=1.3061 acc=0.4645\n",
      "epoch 129, train, loss=2.2420 acc=0.3010\n",
      "epoch 129, val, loss=1.3037 acc=0.4693\n",
      "epoch 130, train, loss=2.2900 acc=0.2877\n",
      "epoch 130, val, loss=1.3016 acc=0.4666\n",
      "epoch 131, train, loss=2.2783 acc=0.2959\n",
      "epoch 131, val, loss=1.3003 acc=0.4683\n",
      "epoch 132, train, loss=2.2909 acc=0.2896\n",
      "epoch 132, val, loss=1.3109 acc=0.4617\n",
      "epoch 133, train, loss=2.2782 acc=0.2936\n",
      "epoch 133, val, loss=1.3050 acc=0.4675\n",
      "epoch 134, train, loss=2.2674 acc=0.2957\n",
      "epoch 134, val, loss=1.3059 acc=0.4642\n",
      "epoch 135, train, loss=2.2686 acc=0.2956\n",
      "epoch 135, val, loss=1.3018 acc=0.4665\n",
      "epoch 136, train, loss=2.2716 acc=0.2974\n",
      "epoch 136, val, loss=1.3063 acc=0.4676\n",
      "epoch 137, train, loss=2.2694 acc=0.2979\n",
      "epoch 137, val, loss=1.3036 acc=0.4671\n",
      "epoch 138, train, loss=2.2397 acc=0.3020\n",
      "epoch 138, val, loss=1.3039 acc=0.4674\n",
      "epoch 139, train, loss=2.2963 acc=0.2855\n",
      "epoch 139, val, loss=1.3075 acc=0.4635\n",
      "epoch 140, train, loss=2.2623 acc=0.3024\n",
      "epoch 140, val, loss=1.3038 acc=0.4642\n",
      "epoch 141, train, loss=2.2655 acc=0.2991\n",
      "epoch 141, val, loss=1.3039 acc=0.4645\n",
      "epoch 142, train, loss=2.2689 acc=0.2952\n",
      "epoch 142, val, loss=1.3027 acc=0.4661\n",
      "epoch 143, train, loss=2.2539 acc=0.2979\n",
      "epoch 143, val, loss=1.3049 acc=0.4657\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50769/2323358912.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_rec/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_rec/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_rec/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_rec/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_rec/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_rec/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_rec/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_rec/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph_rec/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.max_epoch + 1):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "\n",
    "    for i in range(100):\n",
    "        sx, sy, qx, qy  = next(iter(train_loader))\n",
    "        data = torch.cat((sx, qx), dim=1)\n",
    "        labels = torch.cat((sy, qy), dim=1)\n",
    "        batch = (data, labels)\n",
    "        torch.cuda.empty_cache()\n",
    "        loss, acc = fast_adapt(model,\n",
    "                                batch,\n",
    "                                args.train_ways,\n",
    "                                args.shot,\n",
    "                                args.train_query,\n",
    "                                metric=pairwise_distances_logits,\n",
    "                                device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print('epoch {}, train, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        sx, sy, qx, qy  = batch\n",
    "        data = torch.cat((sx, qx), dim=1)\n",
    "        labels = torch.cat((sy, qy), dim=1)\n",
    "        batch = (data, labels)\n",
    "        loss, acc = fast_adapt(model,\n",
    "                                batch,\n",
    "                                args.test_ways,\n",
    "                                args.test_shot,\n",
    "                                args.test_query,\n",
    "                                metric=pairwise_distances_logits,\n",
    "                                device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "    print('epoch {}, val, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n",
    "\n",
    "loss_ctr = 0\n",
    "n_acc = 0\n",
    "\n",
    "for i, batch in enumerate(test_loader, 1):\n",
    "    sx, sy, qx, qy  = batch\n",
    "    data = torch.cat((sx, qx), dim=1)\n",
    "    labels = torch.cat((sy, qy), dim=1)\n",
    "    batch = (data, labels)\n",
    "    loss, acc = fast_adapt(model,\n",
    "                            batch,\n",
    "                            args.test_ways,\n",
    "                            args.test_shot,\n",
    "                            args.test_query,\n",
    "                            metric=pairwise_distances_logits,\n",
    "                            device=device)\n",
    "    loss_ctr += 1\n",
    "    n_acc += acc\n",
    "    print('batch {}: {:.2f}({:.2f})'.format(\n",
    "        i, n_acc/loss_ctr * 100, acc * 100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b04a425eb4e2f19ba39b3c02446514a59b882cc39dc361899bc0b5cea762b69"
  },
  "kernelspec": {
   "display_name": "graph_rec",
   "language": "python",
   "name": "graph_rec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

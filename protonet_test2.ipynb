{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.dataloader import MiniImagenet\n",
    "from proto.protonet import ConvNet, distance, accuracy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(777)\n",
    "torch.cuda.manual_seed_all(777)\n",
    "np.random.seed(777)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances_logits(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    logits = -((a.unsqueeze(1).expand(n, m, -1) -\n",
    "                b.unsqueeze(0).expand(n, m, -1))**2).sum(dim=2)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)\n",
    "\n",
    "def proto_train(model, batch, ways, shot, query_num, metric=None, device=None):\n",
    "    if metric is None:\n",
    "        metric = pairwise_distances_logits\n",
    "    if device is None:\n",
    "        device = model.device()\n",
    "    data, labels = batch\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    n_items = shot * ways\n",
    "\n",
    "    # Sort data samples by labels\n",
    "    # TODO: Can this be replaced by ConsecutiveLabels ?\n",
    "    sort = torch.sort(labels)\n",
    "    data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "    labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "    # Compute support and query embeddings\n",
    "    embeddings = model(data)\n",
    "    support_indices = np.zeros(data.size(0), dtype=bool)\n",
    "    selection = np.arange(ways) * (shot + query_num)\n",
    "    for offset in range(shot):\n",
    "        support_indices[selection + offset] = True\n",
    "    query_indices = torch.from_numpy(~support_indices)\n",
    "    support_indices = torch.from_numpy(support_indices)\n",
    "    support = embeddings[support_indices]\n",
    "    support = support.reshape(ways, shot, -1).mean(dim=1)\n",
    "    query = embeddings[query_indices]\n",
    "    labels = labels[query_indices].long()\n",
    "\n",
    "    logits = pairwise_distances_logits(query, support)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    acc = accuracy(logits, labels)\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = EasyDict({\n",
    "    'max_epoch':250,\n",
    "    'train_ways':20,\n",
    "    'shot' : 1,\n",
    "    'train_query':15,\n",
    "    'test_ways': 5,\n",
    "    'test_shot' : 1,\n",
    "    'test_query':15,\n",
    "    'batch_size':1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:35<00:00, 711.70it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 2001.36it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 2691.19it/s]\n"
     ]
    }
   ],
   "source": [
    "root_path = './datasets/miniimagenet/pkl_file/' \n",
    "train_dataset = MiniImagenet(path=root_path, N=args.train_ways, K=args.shot, Q=args.train_query, \\\n",
    "                             mode='train', total_iter=25000,\\\n",
    "                             transform=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size,\\\n",
    "                          shuffle=True, num_workers=1)\n",
    "val_dataset = MiniImagenet(path=root_path, N=args.test_ways, K=args.test_shot, Q=args.test_query,\\\n",
    "                           mode='validation', total_iter=200,\\\n",
    "                           transform=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size,\\\n",
    "                        shuffle=True, num_workers=1)\n",
    "test_dataset = MiniImagenet(path=root_path, N=args.test_ways, K=args.test_shot, Q=args.test_query,\\\n",
    "                            mode='test', total_iter=2000,\\\n",
    "                            transform=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size,\\\n",
    "                         shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = ConvNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sx, sy, qx, qy = task_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/graph_rec/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train, loss=21.4716 acc=0.1090\n",
      "epoch 1, val, loss=2.2749 acc=0.2695\n",
      "epoch 2, train, loss=3.2944 acc=0.1064\n",
      "epoch 2, val, loss=1.7410 acc=0.2777\n",
      "epoch 3, train, loss=3.0188 acc=0.1142\n",
      "epoch 3, val, loss=1.6169 acc=0.3013\n",
      "epoch 4, train, loss=2.9225 acc=0.1297\n",
      "epoch 4, val, loss=1.5767 acc=0.3173\n",
      "epoch 5, train, loss=2.8752 acc=0.1376\n",
      "epoch 5, val, loss=1.5513 acc=0.3249\n",
      "epoch 6, train, loss=2.8512 acc=0.1419\n",
      "epoch 6, val, loss=1.5514 acc=0.3328\n",
      "epoch 7, train, loss=2.8202 acc=0.1502\n",
      "epoch 7, val, loss=1.5160 acc=0.3433\n",
      "epoch 8, train, loss=2.8233 acc=0.1440\n",
      "epoch 8, val, loss=1.5025 acc=0.3522\n",
      "epoch 9, train, loss=2.7951 acc=0.1533\n",
      "epoch 9, val, loss=1.5004 acc=0.3583\n",
      "epoch 10, train, loss=2.7790 acc=0.1551\n",
      "epoch 10, val, loss=1.4783 acc=0.3631\n",
      "epoch 11, train, loss=2.7474 acc=0.1742\n",
      "epoch 11, val, loss=1.4786 acc=0.3661\n",
      "epoch 12, train, loss=2.7601 acc=0.1666\n",
      "epoch 12, val, loss=1.4873 acc=0.3693\n",
      "epoch 13, train, loss=2.7089 acc=0.1810\n",
      "epoch 13, val, loss=1.4572 acc=0.3813\n",
      "epoch 14, train, loss=2.7078 acc=0.1798\n",
      "epoch 14, val, loss=1.4474 acc=0.3890\n",
      "epoch 15, train, loss=2.6984 acc=0.1855\n",
      "epoch 15, val, loss=1.4502 acc=0.3850\n",
      "epoch 16, train, loss=2.6927 acc=0.1871\n",
      "epoch 16, val, loss=1.4667 acc=0.3845\n",
      "epoch 17, train, loss=2.6839 acc=0.1900\n",
      "epoch 17, val, loss=1.4464 acc=0.3882\n",
      "epoch 18, train, loss=2.6657 acc=0.1930\n",
      "epoch 18, val, loss=1.4541 acc=0.3893\n",
      "epoch 19, train, loss=2.6652 acc=0.1966\n",
      "epoch 19, val, loss=1.4252 acc=0.4027\n",
      "epoch 20, train, loss=2.6931 acc=0.1838\n",
      "epoch 20, val, loss=1.4327 acc=0.3957\n",
      "epoch 21, train, loss=2.6297 acc=0.2005\n",
      "epoch 21, val, loss=1.4258 acc=0.4001\n",
      "epoch 22, train, loss=2.6248 acc=0.2046\n",
      "epoch 22, val, loss=1.4260 acc=0.3969\n",
      "epoch 23, train, loss=2.6094 acc=0.2065\n",
      "epoch 23, val, loss=1.4512 acc=0.3903\n",
      "epoch 24, train, loss=2.6008 acc=0.2106\n",
      "epoch 24, val, loss=1.3993 acc=0.4101\n",
      "epoch 25, train, loss=2.5950 acc=0.2100\n",
      "epoch 25, val, loss=1.4194 acc=0.4101\n",
      "epoch 26, train, loss=2.6140 acc=0.2067\n",
      "epoch 26, val, loss=1.4480 acc=0.3985\n",
      "epoch 27, train, loss=2.5869 acc=0.2167\n",
      "epoch 27, val, loss=1.4067 acc=0.4086\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.max_epoch + 1):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "\n",
    "    for i in range(100):\n",
    "        sx, sy, qx, qy  = next(iter(train_loader))\n",
    "        data = torch.cat((sx, qx), dim=1)\n",
    "        labels = torch.cat((sy, qy), dim=1)\n",
    "        batch = (data, labels)\n",
    "        torch.cuda.empty_cache()\n",
    "        loss, acc = proto_train(model,\n",
    "                                batch,\n",
    "                                args.train_ways,\n",
    "                                args.shot,\n",
    "                                args.train_query,\n",
    "                                metric=pairwise_distances_logits,\n",
    "                                device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print('epoch {}, train, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n",
    "\n",
    "    model.eval()\n",
    "    loss_ctr = 0\n",
    "    n_loss = 0\n",
    "    n_acc = 0\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        sx, sy, qx, qy  = batch\n",
    "        data = torch.cat((sx, qx), dim=1)\n",
    "        labels = torch.cat((sy, qy), dim=1)\n",
    "        batch = (data, labels)\n",
    "        loss, acc = proto_train(model,\n",
    "                                batch,\n",
    "                                args.test_ways,\n",
    "                                args.test_shot,\n",
    "                                args.test_query,\n",
    "                                metric=pairwise_distances_logits,\n",
    "                                device=device)\n",
    "\n",
    "        loss_ctr += 1\n",
    "        n_loss += loss.item()\n",
    "        n_acc += acc\n",
    "\n",
    "    print('epoch {}, val, loss={:.4f} acc={:.4f}'.format(\n",
    "        epoch, n_loss/loss_ctr, n_acc/loss_ctr))\n",
    "\n",
    "loss_ctr = 0\n",
    "n_acc = 0\n",
    "\n",
    "for i, batch in enumerate(test_loader, 1):\n",
    "    sx, sy, qx, qy  = batch\n",
    "    data = torch.cat((sx, qx), dim=1)\n",
    "    labels = torch.cat((sy, qy), dim=1)\n",
    "    batch = (data, labels)\n",
    "    loss, acc = proto_train(model,\n",
    "                            batch,\n",
    "                            args.test_ways,\n",
    "                            args.test_shot,\n",
    "                            args.test_query,\n",
    "                            metric=pairwise_distances_logits,\n",
    "                            device=device)\n",
    "    loss_ctr += 1\n",
    "    n_acc += acc\n",
    "    print('batch {}: {:.2f}({:.2f})'.format(\n",
    "        i, n_acc/loss_ctr * 100, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b04a425eb4e2f19ba39b3c02446514a59b882cc39dc361899bc0b5cea762b69"
  },
  "kernelspec": {
   "display_name": "graph_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
